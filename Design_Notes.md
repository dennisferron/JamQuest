# Design Notes, Work in Progress

The TMX format supports a hierarchy of layers.  The layer types can be tiles, objects, text, image, or a group which contains other layers.  Everything needs to be drawn (composited) in order.

This seems clearly a job for class (inheritance) based polymorphism.  We can have a base Layer class with a pure virtual draw method, and implement for the different layer types.  If we use a LayerGroup as our root object, we get management of the root list of layers for free.

(An alternate possibility would be to use the libTMX data structures as-is.  I would worry that could lead to a mismatch between the feature and performance needs of the game versus what was implemented with only TMX files in mind.  However the organization of the libTMX data structures do provide a template for initial organization of a 2D game's data structures.)

Presumably we will need to display things (score, player, spawned enemies) that weren't in the TMX file, but we want them to be situated within the hierarchy (draw order) of the map layers.  We need to somehow connect instances of our Layer objects with keys by which other parts of the game code can find them to say on what layer something should be drawn.  The TMX layers have an id, but they seem to be auto-numbered; the id isn't editable in Tiled.  We could use the name of the layer as the key linking it to game code.  Or, we could use a custom property.  Not sure yet which of those two is best.

A strategy consideration is whether a list of things to be drawn is generated per-frame (based on what's visible), or if the overall world layers individually determine what's in their viewport and directly draw their contents.  An obvious point against the per-frame draw list is that either generating from scratch or putting things in and out of this list could be time consuming (either of programmer tedium, or game frame performance).  In practice I don't know how much or little impact that would have.  A point in favor is that it would help with debugging when something isn't showing up as expected by separating "should this be displayed" (in the draw list or not) from "how does this display" (what does the screen look like when it is drawn).

The details of the draw list itself raise further questions about this design choice.  We could have a homogenous list of drawable items (base class), with derived implementations draw a tile, draw a sprite, draw a polyline, image section, etc.  This feels wrong; like-typed objects should be drawn in a batch rather than virtually dispatched for every individual tile or line.  (On the other hand how much of a performance hit is it?)  However since layer order must be respected, in the limit this just becomes the same as the hierarchy of layer objects, except containing only the viewport tiles instead of the whole world or level.  Thus begging the question of how this differs from the other design.  Would the world / level layers each manage a viewport doppelganger? 

TODO: Talk about rendering to multiple views.

As well as representing the map on the screen, the map tiles and objects need to be represented in the game world for physics purposes (and possibly, game AI - e.g. pathing).  This also ties into the question of whether the map tiles draw themselves or put something into a draw list, because there is also the question whether the physics-world objects draw themselves or interact with a display subsystem.  Especially if we're rendering multiple views with different parameters (such as an in-game representation of a closed-circuit TV camera screen), then it seems potentially messy to "let" the game objects and level render themselves.

A separation of concerns into core game objects and level data that is different from the map layer objects could also provide a way to get around the design question about whether the map layers draw themselves or create a draw list.  What we could do is say that yes, the TMX *map* layer objects do draw themselves, but these Layer classes form part of a display subsystem that relieves the core game objects of the burden of drawing *themselves*.  In a way the Layer objects would be like a "smart" draw list implementation.

Now that we've established a separation of concerns by saying that the drawing Layer objects are different than the core game objects used by physics and game AI, it reveals a new aspect which wasn't clear before.  We can now see that it would be desirable for a single core game object to be able to be represented on multiple display layers.  For example a middle-layer map tile that is "on fire" might also cast a glow on the sky/background layer and sparks or smoke on the foreground layer.  Similarly a boss enemy might have a shadow on the background layer and miasma on the foreground layer.  So there's a one-to-many relationship between core "tiles" and game objects.

This raises the question of whether we process the reverse of that many-to_one relationship during map loading.  Are core game objects especially tiles synthesized by compiling multiple layers' information together?  (Alternatively things like the "on fire" tile could only exist in the middle layer in the TMX file and other display layer effects would only be visible in-game.)  If we do go down the route of combining things across TMX Z-layers into one game object, we could also think of compiling multiple tiles in X and Y into a single block for physics purposes if we use Bullet physics.

That last point then leads to a further question whether we organize the tiles associated with the physics object so that they are part of a group with a common parallax_offset, which could change in world-space if the physics object can move.  It could do effects like a house that moves due to some RPG game event, or a section of a level moving like a platform in a side scroller.  This would seem to be turning a tile-based rendering engine into a hierarchical scene node renderer, like a 2D-OGRE.

That is starting to sound overly complex.  A hierarchical scene node renderer would need to use bounding boxes and recursively calculate what's visible, where.  However what we could do is leave that for a future extension.  In the meantime we could just implement a TileGridLayer that has a uniform tile grid with a single parallax_offset in world coordinates.  It could be extended to support smaller movable sections using a further derived class implemented later if at all.